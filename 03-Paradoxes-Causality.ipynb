{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paradoxes and Resolutions\n",
    "\n",
    "## \"One crazy trick to succeed at programming\"\n",
    "\n",
    "<img src='images/sim1.png' width=500>\n",
    "\n",
    "__Coding speed (x) vs. error rate (y)__: \"Just write your code really fast!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really?\n",
    "\n",
    "<img src='images/sim2.png' width=500>\n",
    "\n",
    "__Novices (blue) vs. senior engineers (orange)__: \"Not so much\"\n",
    "\n",
    "This is an example of *Simpson's Paradox*. Look: the data really are the same...\n",
    "\n",
    "<img src='images/sim.png' width=500>\n",
    "\n",
    "See also: https://en.wikipedia.org/wiki/Simpson's_paradox\n",
    "\n",
    "__Overcontrol__\n",
    "\n",
    "But now ... that's why my team lead said \"control for everything\" ... doesn't that help?\n",
    "\n",
    "__No.__\n",
    "\n",
    "For a mathematical demonstration, see Pearl; for intuition, we'll come back to this soon when we discuss causality and \"causal salad.\"\n",
    "\n",
    "In the meantime, here's a silly counterexample that will stick with you: see `images/simpsonreverse.mp4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reverse problem ... or \"closing those tricky sales prospects\"\n",
    "\n",
    "<img src='images/deal.svg' width=700>\n",
    "\n",
    "#### Why do we keep getting big-volume deals at low margin and high-margin deals at low volume? Can't we change this?\n",
    "\n",
    "### Let's take a look at all the original leads\n",
    "\n",
    "<img src='images/berk1.png' width=600>\n",
    "\n",
    "### Now let's look at what's getting through our sales-priority assignments\n",
    "\n",
    "<img src='images/berk2.png' width=600>\n",
    "\n",
    "#### This is an example of *Berkson's Paradox*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do these paradoxes have in common?\n",
    "\n",
    "#### Here's a hint ... we know this chart (below) is silly ... but why?\n",
    "<img src='images/pirates.png' width=700>\n",
    "\n",
    "#### We joke about plots like this and say\n",
    "\n",
    "> <p style=\"font-size:1.5em\">\"Correlation is not causation\"</p>\n",
    "\n",
    "#### But the reality is that, especially in business, most of the time what we are interested in is causation.\n",
    "\n",
    "__Why? Because in business -- usually -- the data relationship in the abstract is not what we're interested in.__\n",
    "\n",
    "* We're interested in making money, or some practices that will lead in that direction\n",
    "    * More sales\n",
    "    * Better products\n",
    "    * The right kind of innovation\n",
    "    * Advantage in the market\n",
    "    * etc.\n",
    "* And we want to __intervene__ in the world to __cause__ those outcomes.\n",
    "\n",
    "Which means we need to learn about causal inference if we want to make good business decisions.\n",
    "\n",
    "Causal inference is hard, for a number of reasons...\n",
    "1. It requires more complex techniques and deeper understanding\n",
    "2. We (in business) often start with *descriptive analytics* and then move on to *predictive modeling* and, paradoxically, \n",
    "> \"Models that are causally incorrect can make better predictions than those that are causally correct. As a result, focusing on predictions can systematically mislead us.\" - R. McElreath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why, consider that the two (causal vs. predictive) approaches are trying to answer different questions. \n",
    "\n",
    "* A predictive model can tell me where in Toronto I will likely find less poverty and it may be very accurate in that regard. \n",
    "* That is totally different from the causal question \n",
    "    * What causes poverty? \n",
    "    * or, more precisely, *If* I want to reduce poverty in Toronto, *what intervention* might I try, and *what effect size* might I expect?\n",
    "3. (maybe the gnarliest from a philosophical point of view) __Observational data alone cannot establish causality; parts of the causal hypothesis to test must come from *outside* the data and modeling exercise.__\n",
    "    * In certain cases, i.e., with strong assumptions about linearity, we can bend this rule ... but then again, if we assume linearity, that's also coming from outside the data and modeling exercise...\n",
    "\n",
    "This certainly throws a monkeywrench into a lot of weakly informed \"data driven\" processes. But...\n",
    "\n",
    "#### It's not quite as bad as it might seem...\n",
    "\n",
    "Our business domain knowledge (and common sense) can often allow us to articulate a causal hypothesis.\n",
    "\n",
    "For example, suppose (A) is my firm's holiday discount and (B) is increased sales volume during the subsequent holiday season. We observe a correlation.\n",
    "\n",
    "We know that \"B causes A\" (I'll write it as B -> A) makes no sense. (In the traditional sense of cause, although even that is up for debate: the \"prospect\" of B might be considered to cause A via an agent, but let's not get too far down that rabbit hole.)\n",
    "\n",
    "A -> B is *possible*\n",
    "\n",
    "And we might want to investigate:\n",
    "\n",
    "Does A cause B? (A -> B)\n",
    "\n",
    "or does something else cause both B and A, creating the correlation I observe:\n",
    "\n",
    "<img src='images/conf.svg'>\n",
    "\n",
    "where (C) is, for example, a holiday season or end-of-year budget period\n",
    "\n",
    "In this latter example, C is called a \"confound\" and we might want to test its role by controlling for this factor in our analysis. __In fact, this is exactly what caused our Simpson's Paradox example, above.__ \n",
    "\n",
    "In that example, \n",
    "* the *experience level* of the programmer was the (C) variable correlated both \n",
    "    * positively with coding speed (A) \n",
    "    * and negatively with error rates (B), \n",
    "* while A and B have their own correlation (higher coding speed is correlated with higher error rates)\n",
    "    * which we could observe once we controlled for (C)\n",
    "\n",
    "So maybe the answer is to sketch out everything we can think of (or measure) and control for all of it!\n",
    "\n",
    "Many a researcher has taken that route, but that is not quite subtle enough. Richard McElreath calls that __Causal Salad__\n",
    "\n",
    "> \"Causal Salad means tossing various 'control' variables into a statistical model, observing changes in estimates, and then telling a story about causation. Causal salad seems founded on the notion that only omitted variables can mislead us about causation. But *included* variables can just as easily confound us.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colliders and Berkson's Paradox\n",
    "\n",
    "The causal salad problem is exactly what happened with our sales deal example of Berkson's Paradox. \n",
    "\n",
    "We had (A) deal volume and (B) deal margin which were, in the raw data, uncorrelated. \n",
    "\n",
    "We also had a factor (C) which amounted to how easy it was to get a deal through the sales process.\n",
    "Both (A) and (B) affected (C): lower volume __or__ lower margin deals are easier to sell.\n",
    "\n",
    "Graphically, it looked like this:\n",
    "\n",
    "<img src='images/collider.svg'>\n",
    "\n",
    "We then ... perhaps unconsciously ... conditioned on (C): that is, the deals we pursued and closed were related based on how easy it was to get them through the sales process. Controlling on C (called __conditioning on a collider__) created a spurious correlation between (A) and (B).\n",
    "\n",
    "Another classic example of Berkson's Paradox, or conditioning on a collider, is an MBA (management degree) program which discovers that its students seem to be smarter (but worse leaders) or stronger leaders (but less smart).\n",
    "* Their admissions and grading processes effectively condition on \"success\" -- i.e., picking students by an approximation of a \"success\" attribute -- which is composed of both leadership and smartness (at least in the example.)\n",
    "* The result is an induced negative correlation between perceived smartness and leadership ability in their grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Takeaway\n",
    "\n",
    "At this point, you might be feeling like any way you go with statistical analyses, you may get into trouble.\n",
    "\n",
    "* Honestly, that's a good defensive posture for any statistician\n",
    "* But it also makes it really hard to get your job done!\n",
    "\n",
    "#### The lesson here is not to give up, but to look a bit skeptically at \"__data is the new oil__\" or \"__data-driven__\" hype.\n",
    "\n",
    "The data we have is, in fact quite useful... but not by itself. \n",
    "\n",
    "We need to start with \n",
    "* a human understanding of the business rules and patterns, \n",
    "* serious thinking about causality, \n",
    "* and then perform analyses to see whether the data provides evidence for actions that will help us reach our goals.\n",
    "\n",
    "I call this approach *data driven with smart models* because the models that produce value don't come purely from the data, but partly from data and partly from thoughtful humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
